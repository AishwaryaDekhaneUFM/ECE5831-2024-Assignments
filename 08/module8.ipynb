{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b9f4dbc4-88de-4d9d-b0fe-c3d94b49552b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f1965c3c-1f2d-4d5f-8b97-e91fb6945d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "32cf328c-93e7-4ea4-ad31-fbc131d0cb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "51227c97-1e53-4902-937a-7013f943cd59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e39b8332-7395-4001-b6c6-da8d2bd4acc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2e006a81-094a-4351-b5ac-6b48a6aaf3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2832fa8b0>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[500]/255, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1ef429-94ec-4f24-bc8a-493ae07f0d33",
   "metadata": {},
   "source": [
    "# TwoLayerNet in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "16cded27-63da-416b-92d9-94a48b2e0780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9493132f-20ec-45e1-a7dc-d638d411c424",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"sigmoid\", input_shape=(784, )),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ccf87618-b908-4605-b1a9-8a5112a7a716",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"SGD\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d4386007-36c2-4a1a-bf34-ece56e4b1304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9915328d-7a4b-4c62-a987-40904af93cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f62217b7-a33e-4fe3-a789-634999a49dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d1435b0b-e9a3-46b3-97e2-f465a1c8e3a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0843f1c4-5718-48e3-ae52-72ccb0f081df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.to_categorical(y_train, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958f57f9-8c16-4b4d-8a74-0bb3793862c6",
   "metadata": {},
   "source": [
    "## Preprocess datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "911174d0-c201-42d0-b2ea-656e51ad80d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape 28x28 to 784\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2])\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1]*x_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1f29bc5d-0ca0-42a1-bfd1-97bea164d7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "89fc136e-ae92-4865-98f8-5291f9665fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize values to 0 .. 1\n",
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f1bb02d4-c709-446c-a083-f5ea1dfc5d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test =  keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "31f0896e-5a79-408b-afc8-e1958af481ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7b398451-5ddf-4ea6-a25c-3c0f5c398942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 1s 384us/step - loss: 1.4564 - accuracy: 0.6935\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 1s 382us/step - loss: 0.7217 - accuracy: 0.8432\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 1s 381us/step - loss: 0.5357 - accuracy: 0.8702\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 1s 382us/step - loss: 0.4561 - accuracy: 0.8828\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 1s 385us/step - loss: 0.4118 - accuracy: 0.8903\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 1s 386us/step - loss: 0.3833 - accuracy: 0.8953\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 1s 380us/step - loss: 0.3630 - accuracy: 0.8990\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 1s 387us/step - loss: 0.3474 - accuracy: 0.9029\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 1s 440us/step - loss: 0.3353 - accuracy: 0.9049\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 1s 386us/step - loss: 0.3251 - accuracy: 0.9078\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 1s 388us/step - loss: 0.3165 - accuracy: 0.9099\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 1s 391us/step - loss: 0.3089 - accuracy: 0.9120\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 1s 379us/step - loss: 0.3021 - accuracy: 0.9134\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 1s 376us/step - loss: 0.2961 - accuracy: 0.9148\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 1s 385us/step - loss: 0.2905 - accuracy: 0.9160\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 1s 406us/step - loss: 0.2852 - accuracy: 0.9178\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 1s 387us/step - loss: 0.2805 - accuracy: 0.9191\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 1s 386us/step - loss: 0.2757 - accuracy: 0.9205\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 1s 383us/step - loss: 0.2714 - accuracy: 0.9218\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 1s 383us/step - loss: 0.2671 - accuracy: 0.9233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x283740970>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "23f94d2a-9c65-47e3-8817-73587eb7a918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x283745af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x283745af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "65de1d19-8ee3-4b5e-82f4-39513d6151d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d30992b6-800c-42b8-8437-d773cfcc0a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fd3bd067-b523-482d-a8f2-55924838eb83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4, 1, 4, 9, 6, 9])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "be2e6305-e55b-40ec-8a39-195021e8092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.argmax(y_test[0:10], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1e520c0d-d3e8-4a11-8465-996f9fea17b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "de8c92bc-6d73-496c-9d95-08f84deb4205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions == labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1060440-952f-4da0-9fd4-c925ecd7a960",
   "metadata": {},
   "source": [
    "# LeNet in Keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7d40c616-5c27-4206-b326-08fd7f9c90d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model, save_model\n",
    "from keras.layers import Conv2D, AveragePooling2D, Flatten, Dense\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8c4cf8a9-4d4d-4c18-93e9-d2cfa828b904",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet:\n",
    "    def __init__(self, batch_size=32, epochs=20):\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.model = None\n",
    "        self._create_lenet()\n",
    "        self._compile()\n",
    "    \n",
    "\n",
    "    def _create_lenet(self):\n",
    "        self.model = Sequential([\n",
    "            Conv2D(filters=6, kernel_size=(5,5), \n",
    "                   activation='sigmoid', input_shape=(28, 28, 1), \n",
    "                   padding='same'),\n",
    "            AveragePooling2D(pool_size=(2, 2), strides=2),\n",
    "            \n",
    "            Conv2D(filters=16, kernel_size=(5,5), \n",
    "                   activation='sigmoid', \n",
    "                   padding='same'),\n",
    "            AveragePooling2D(pool_size=(2, 2), strides=2),\n",
    "\n",
    "            Flatten(),\n",
    "\n",
    "            Dense(120, activation='sigmoid'),\n",
    "            Dense(84, activation='sigmoid'),\n",
    "            Dense(10, activation='softmax')\n",
    "        ])\n",
    "\n",
    "    def _compile(self):\n",
    "        if self.model is None:\n",
    "            print('Error: Create a model first..')\n",
    "        \n",
    "        self.model.compile(optimizer='Adam',\n",
    "                           loss='categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "        \n",
    "\n",
    "    def _preprocess(self):\n",
    "        # load mnist data\n",
    "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "        # normalize\n",
    "        x_train = x_train/255.0\n",
    "        x_test = x_test/255.0\n",
    "\n",
    "        # add channel dim\n",
    "        self.x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)  \n",
    "        self.x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)  \n",
    "\n",
    "        # one-hot encoding\n",
    "        self.y_train = to_categorical(y_train, 10)\n",
    "        self.y_test = to_categorical(y_test, 10)\n",
    "\n",
    "    def train(self):\n",
    "        self._preprocess()\n",
    "        self.model.fit(self.x_train, self.y_train, \n",
    "                  batch_size=self.batch_size, \n",
    "                  epochs=self.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8dd28b04-57ab-4070-8b20-8f2f5e892325",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet = LeNet(batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f8d8df22-a22d-47f8-8b8a-4cd207a5d86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.9934 - accuracy: 0.6728\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 0.2296 - accuracy: 0.9304\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.1515 - accuracy: 0.9538\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 0.1138 - accuracy: 0.9646\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.0915 - accuracy: 0.9716\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 0.0762 - accuracy: 0.9762\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 0.0657 - accuracy: 0.9800\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 0.0579 - accuracy: 0.9822\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 0.0518 - accuracy: 0.9843\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.0480 - accuracy: 0.9847\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lenet.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d5ace0d3-e0e8-436c-8856-ccfc5b3340a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x2837bfa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x2837bfa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = np.argmax(lenet.model.predict(lenet.x_test[0:10]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "37a43709-9183-40f1-9cc9-772ec6142729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 5 9]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "105044d9-f849-4b30-8c3c-3d7a53a055b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.argmax(lenet.y_test[0:10], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "da94f270-8b5c-4696-9340-f0a2bf80d976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 5 9]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "72c5cbbd-5242-4182-8877-af91e3e0595d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "print(predictions == labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d94b327a-37fd-4d96-9cbe-ad327326c5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet:\n",
    "    def __init__(self, batch_size=32, epochs=10):\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.model = None\n",
    "        self._create_lenet()\n",
    "        self._compile()\n",
    "    \n",
    "    def _create_lenet(self):\n",
    "        self.model = Sequential([\n",
    "            Conv2D(filters=6, kernel_size=(5,5), \n",
    "                   activation='sigmoid', input_shape=(28, 28, 1), \n",
    "                   padding='same'),\n",
    "            AveragePooling2D(pool_size=(2, 2), strides=2),\n",
    "            \n",
    "            Conv2D(filters=16, kernel_size=(5,5), \n",
    "                   activation='sigmoid', \n",
    "                   padding='same'),\n",
    "            AveragePooling2D(pool_size=(2, 2), strides=2),\n",
    "\n",
    "            Flatten(),\n",
    "\n",
    "            Dense(120, activation='sigmoid'),\n",
    "            Dense(84, activation='sigmoid'),\n",
    "            Dense(10, activation='softmax')\n",
    "        ])\n",
    "\n",
    "    def _compile(self):\n",
    "        if self.model is None:\n",
    "            print('Error: Create a model first..')\n",
    "        \n",
    "        self.model.compile(optimizer='Adam',\n",
    "                           loss='categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "        \n",
    "\n",
    "    def _preprocess(self):\n",
    "        # load mnist data\n",
    "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "        # normalize\n",
    "        x_train = x_train / 255.0\n",
    "        x_test = x_test / 255.0\n",
    "\n",
    "        # add channel dim\n",
    "        self.x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)  \n",
    "        self.x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)  \n",
    "\n",
    "        # one-hot encoding\n",
    "        self.y_train = to_categorical(y_train, 10)\n",
    "        self.y_test = to_categorical(y_test, 10)\n",
    "\n",
    "    def train(self):\n",
    "        self._preprocess()\n",
    "        self.model.fit(self.x_train, self.y_train, \n",
    "                  batch_size=self.batch_size, \n",
    "                  epochs=self.epochs, \n",
    "                  validation_data=(self.x_test, self.y_test))\n",
    "    \n",
    "    def save(self, model_path_name):\n",
    "        save_model(self.model, f\"{model_path_name}_cnn_model.keras\")\n",
    "        print(f\"Model saved as {model_path_name}_cnn_model.keras\")\n",
    "\n",
    "    def load(self, model_path_name):\n",
    "        self.model = load_model(f\"{model_path_name}_cnn_model.keras\")\n",
    "        print(f\"Model loaded from {model_path_name}_cnn_model.keras\")\n",
    "\n",
    "    def predict(self, images):\n",
    "        if self.model is None:\n",
    "            print(\"Model is not loaded or trained.\")\n",
    "            return None\n",
    "        \n",
    "        # Preprocess images (normalize and add channel dimension)\n",
    "        images = [img / 255.0 for img in images]  # normalize each image\n",
    "        images = np.array(images).reshape(-1, 28, 28, 1)  # reshape with channel dimension\n",
    "        \n",
    "        predictions = self.model.predict(images)\n",
    "        return predictions.argmax(axis=1)  # return the class with the highest probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "de78bd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.7392 - accuracy: 0.7594 - val_loss: 0.2157 - val_accuracy: 0.9368\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1763 - accuracy: 0.9460 - val_loss: 0.1178 - val_accuracy: 0.9634\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1134 - accuracy: 0.9653 - val_loss: 0.0855 - val_accuracy: 0.9731\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0845 - accuracy: 0.9743 - val_loss: 0.0663 - val_accuracy: 0.9776\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0680 - accuracy: 0.9788 - val_loss: 0.0690 - val_accuracy: 0.9782\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0579 - accuracy: 0.9821 - val_loss: 0.0484 - val_accuracy: 0.9850\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0491 - accuracy: 0.9846 - val_loss: 0.0437 - val_accuracy: 0.9861\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0427 - accuracy: 0.9869 - val_loss: 0.0437 - val_accuracy: 0.9854\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0384 - accuracy: 0.9880 - val_loss: 0.0456 - val_accuracy: 0.9870\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0336 - accuracy: 0.9894 - val_loss: 0.0398 - val_accuracy: 0.9877\n",
      "Model saved as ipynb_dekhane_cnn_model.keras\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Training the model\n",
    "    lenet = LeNet(batch_size=32)  # You can adjust batch size and epochs as needed\n",
    "    lenet.train()\n",
    "\n",
    "    # Saving the model\n",
    "    lenet.save(\"ipynb_dekhane\")  # Saves as 'your_last_name_cnn_model.keras'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece5831-2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
